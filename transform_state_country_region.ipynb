{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2fbc44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a67e5abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 0.00090 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "# this feature will take the \"STATE/REGION\" and \"COUNTRY/REGION\" from hubspot\n",
    "# clean them from punctuatuion and wrongfuly imported data\n",
    "# output: Record ID, STATE/REGION (cleaned) , COUNTRY/REGION (cleaned), Continent (created based on the state and country)\n",
    "\n",
    "#Input option 1 - Redshift table synced from HS \"hs_contacts\"\n",
    "#Input option 2 - Exported CSV from HubSpot of Record ID, STATE/REGION, COUNTRY/REGION\n",
    "#select only Record ID, STATE/REGION, COUNTRY/REGION \n",
    "\"\"\"\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "con_redshift = wr.redshift.connect(\"redshift-cluster-matil\")\n",
    "\n",
    "hs_contacts = wr.redshift.read_sql_query(\"SELECT * FROM public.hs_contacts\", con=con_redshift)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#func that will remove letters that are not in english\n",
    "\n",
    "\n",
    "\n",
    "def remove_diacritics(input_str):\n",
    "\n",
    "\n",
    "\n",
    "    # Replace English letters with diacritics with their corresponding plain English letters\n",
    "    input_str = re.sub(r\"ß\", \"ss\", input_str)\n",
    "    input_str = re.sub(r\"Š|š\", \"s\", input_str)\n",
    "    input_str = re.sub(r\"Ž|ž\", \"z\", input_str)\n",
    "    input_str = re.sub(r\"À|Á|Â|Ã|Ä|Å|à|á|â|ã|ä|å|æ\", \"a\", input_str)\n",
    "    input_str = re.sub(r\"æ|Æ\", \"ae\", input_str)\n",
    "    input_str = re.sub(r\"Ç|ç|Ç\", \"C\", input_str)\n",
    "    input_str = re.sub(r\"È|É|Ê|Ë|è|é|ê|ë|ë\", \"e\", input_str)\n",
    "    input_str = re.sub(r\"Ì|Í|Î|Ï|ì|í|î|ï\", \"i\", input_str)\n",
    "    input_str = re.sub(r\"Ð\", \"d\", input_str)\n",
    "    input_str = re.sub(r\"Ñ|ñ\", \"n\", input_str)\n",
    "    input_str = re.sub(r\"ð|ò|ó|ô|õ|ö|ø|Ò|Ó|Ô|Õ|Ö|Ø\", \"o\", input_str)\n",
    "    input_str = re.sub(r\"Ù|Ú|Û|Ü|ù|ú|û|ü\", \"u\", input_str)\n",
    "    input_str = re.sub(r\"Ý|ÿ\", \"y\", input_str)\n",
    "    input_str = re.sub(r\"Þ|þ\", \"th\", input_str)\n",
    "    input_str = re.sub(r\"ß\", \"ss\", input_str)\n",
    "    # Replace non-English letters with spaces\n",
    "    input_str = re.sub(r\"[^a-zA-Z\\s]\", \" \", input_str)\n",
    "\n",
    "\n",
    "    \n",
    "    return input_str.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#change long state name to abv for canada\n",
    "def replace_canada_state_name(row):\n",
    "    if pd.isna(row['State/Region']):\n",
    "        return row\n",
    "    for state, abv in canada_states.items():\n",
    "        if state in row['State/Region']:\n",
    "            row['State/Region'] = abv\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "#check if there is a us state in the country column, move it to the correct column and fix the country name\n",
    "def move_state_name(row):\n",
    "    if row['Country/Region'] in us_state_to_abbrev.values():\n",
    "        row['State/Region'] = row['Country/Region']\n",
    "        row['Country/Region'] = 'us'\n",
    "    return row\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to look up the continent for a given country\n",
    "def get_continent(country):\n",
    "    for continent, countries in countries_continents.items():\n",
    "        if country in countries:\n",
    "            return continent\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# United States of America Python Dictionary to translate States,\n",
    "# Districts & Territories to Two-Letter codes and vice versa.\n",
    "#\n",
    "# Canonical URL: https://gist.github.com/rogerallen/1583593\n",
    "#\n",
    "# Dedicated to the public domain.  To the extent possible under law,\n",
    "# Roger Allen has waived all copyright and related or neighboring\n",
    "# rights to this code.  Data originally from Wikipedia at the url:\n",
    "# https://en.wikipedia.org/wiki/ISO_3166-2:US\n",
    "#\n",
    "# Automatically Generated 2021-09-11 18:04:36 via Jupyter Notebook from\n",
    "# https://gist.github.com/rogerallen/d75440e8e5ea4762374dfd5c1ddf84e0 \n",
    "\n",
    "us_state_to_abbrev = {\n",
    "    \"alabama\": \"al\",\n",
    "    \"alaska\": \"ak\",\n",
    "    \"arizona\": \"az\",\n",
    "    \"arkansas\": \"ar\",\n",
    "    \"california\": \"ca\",\n",
    "    \"colorado\": \"co\",\n",
    "    \"connecticut\": \"ct\",\n",
    "    \"delaware\": \"de\",\n",
    "    \"florida\": \"fl\",\n",
    "    \"georgia\": \"ga\",\n",
    "    \"hawaii\": \"hi\",\n",
    "    \"idaho\": \"id\",\n",
    "    \"illinois\": \"il\",\n",
    "    \"indiana\": \"in\",\n",
    "    \"iowa\": \"ia\",\n",
    "    \"kansas\": \"ks\",\n",
    "    \"kentucky\": \"ky\",\n",
    "    \"louisiana\": \"la\",\n",
    "    \"maine\": \"me\",\n",
    "    \"maryland\": \"md\",\n",
    "    \"massachusetts\": \"ma\",\n",
    "    \"michigan\": \"mi\",\n",
    "    \"minnesota\": \"mn\",\n",
    "    \"mississippi\": \"ms\",\n",
    "    \"missouri\": \"mo\",\n",
    "    \"montana\": \"mt\",\n",
    "    \"nebraska\": \"ne\",\n",
    "    \"nevada\": \"nv\",\n",
    "    \"new hampshire\": \"nh\",\n",
    "    \"new jersey\": \"nj\",\n",
    "    \"new mexico\": \"nm\",\n",
    "    \"new york\": \"ny\",\n",
    "    \"north carolina\": \"nc\",\n",
    "    \"north dakota\": \"nd\",\n",
    "    \"ohio\": \"oh\",\n",
    "    \"oklahoma\": \"ok\",\n",
    "    \"oregon\": \"or\",\n",
    "    \"pennsylvania\": \"pa\",\n",
    "    \"rhode island\": \"ri\",\n",
    "    \"south carolina\": \"sc\",\n",
    "    \"south dakota\": \"sd\",\n",
    "    \"tennessee\": \"tn\",\n",
    "    \"texas\": \"tx\",\n",
    "    \"utah\": \"ut\",\n",
    "    \"vermont\": \"vt\",\n",
    "    \"virginia\": \"va\",\n",
    "    \"washington\": \"wa\",\n",
    "    \"west virginia\": \"wv\",\n",
    "    \"west va\": \"wv\",\n",
    "    \"wisconsin\": \"wi\",\n",
    "    \"wyoming\": \"wy\",\n",
    "    \"district of columbia\": \"dc\",\n",
    "    \"american samoa\": \"as\",\n",
    "    \"guam\": \"gu\",\n",
    "    \"northern mariana islands\": \"mp\",\n",
    "    \"puerto rico\": \"pr\",\n",
    "    \"united states minor outlying islands\": \"um\",\n",
    "    \"virgin islands\": \"vi\",\n",
    "}\n",
    "    \n",
    "# invert the dictionary\n",
    "abbrev_to_us_state = dict(map(reversed, us_state_to_abbrev.items()))\n",
    "\n",
    "\n",
    "\n",
    "us_uk_fix = {\n",
    "    \"united states\": \"us\",\n",
    "    \"usa\": \"us\",\n",
    "    \"united kingdom\": \"england\",\n",
    "}\n",
    "\n",
    "\n",
    "#canada states\n",
    "\n",
    "canada_states = {\n",
    "    'alberta': 'ab',\n",
    "    'british columbia': 'bc',\n",
    "    'manitoba': 'mb',\n",
    "    'new brunswick': 'nb',\n",
    "    'newfoundland and labrador': 'nl',\n",
    "    'northwest territories': 'nt',\n",
    "    'nova scotia': 'ns',\n",
    "    'nunavut': 'nu',\n",
    "    'ontario': 'on',\n",
    "    'prince edward island': 'pe',\n",
    "    'quebec': 'qc',\n",
    "    'saskatchewan': 'sk',\n",
    "    'yukon': 'yt'\n",
    "}\n",
    "\n",
    "\n",
    "#DICT of all country names and their continent \n",
    "countries_continents = {'africa': ['algeria', 'angola', 'benin', 'botswana', 'british indian ocean territory', 'burkina faso', 'burundi', 'cabo verde', 'cameroon', 'central african republic', 'chad', 'comoros', 'congo', 'côte d’ivoire', 'democratic republic of the congo', 'djibouti', 'egypt', 'equatorial guinea', 'eritrea', 'eswatini', 'ethiopia', 'french southern territories', 'gabon', 'gambia', 'ghana', 'guinea', 'guinea-bissau', 'kenya', 'lesotho', 'liberia', 'libya', 'madagascar', 'malawi', 'mali', 'mauritania', 'mauritius', 'mayotte', 'morocco', 'mozambique', 'namibia', 'niger', 'nigeria', 'réunion', 'rwanda', 'saint helena', 'sao tome and principe', 'senegal', 'seychelles', 'sierra leone', 'somalia', 'south africa', 'south sudan', 'sudan', 'togo', 'tunisia', 'uganda', 'united republic of tanzania', 'western sahara', 'zambia', 'zimbabwe'], \n",
    "                        'antarctica': ['antarctica'],\n",
    "                        'asia': ['afghanistan', 'armenia', 'azerbaijan', 'bahrain', 'bangladesh', 'bhutan', 'brunei darussalam', 'cambodia', 'china', 'hong kong', 'macao', 'cyprus', \"democratic people's republic of korea\", 'georgia', 'india', 'indonesia', 'iran ', 'iraq', 'israel', 'japan', 'jordan', 'kazakhstan', 'kuwait', 'kyrgyzstan', 'lao ', 'lebanon', 'malaysia', 'maldives', 'mongolia', 'myanmar', 'nepal', 'oman', 'pakistan', 'philippines', 'qatar', 'republic of korea', 'saudi arabia', 'singapore', 'sri lanka', 'state of palestine', 'syrian arab republic', 'tajikistan', 'thailand', 'timor-leste', 'turkey', 'turkmenistan', 'united arab emirates', 'uzbekistan', 'viet nam', 'yemen'],\n",
    "                        'europe': ['aland islands', 'albania', 'andorra', 'austria', 'belarus', 'belgium', 'bosnia and herzegovina', 'bulgaria', 'croatia', 'czechia', 'denmark', 'estonia', 'faroe islands', 'finland', 'france', 'germany', 'gibraltar', 'greece', 'guernsey', 'holy see', 'hungary', 'iceland', 'ireland', 'isle of man', 'italy', 'jersey', 'latvia', 'liechtenstein', 'lithuania', 'luxembourg', 'malta', 'monaco', 'montenegro', 'netherlands', 'north macedonia', 'norway', 'poland', 'portugal', 'republic of moldova', 'romania', 'russian federation', 'san marino', 'sark', 'serbia', 'slovakia', 'slovenia', 'spain', 'svalbard and jan mayen islands', 'sweden', 'switzerland', 'ukraine', 'united kingdom of great britain and northern ireland'],\n",
    "                        'north america': ['anguilla', 'antigua and barbuda', 'aruba', 'bahamas', 'barbados', 'belize', 'bermuda', 'bonaire, sint eustatius and saba', 'british virgin islands', 'canada', 'cayman islands', 'costa rica', 'cuba', 'curacao', 'dominica', 'dominican republic', 'el salvador', 'greenland', 'grenada', 'guadeloupe', 'guatemala', 'haiti', 'honduras', 'jamaica', 'martinique', 'mexico', 'montserrat', 'nicaragua', 'panama', 'puerto rico', 'saint barthélemy', 'saint kitts and nevis', 'saint lucia', 'saint martin', 'saint pierre and miquelon', 'saint vincent and the grenadines', 'sint maarten', 'trinidad and tobago', 'turks and caicos islands', 'us', 'united states virgin islands'],\n",
    "                        'oceania': ['american samoa', 'australia', 'christmas island', 'cocos  islands', 'cook islands', 'fiji', 'french polynesia', 'guam', 'heard island and mcdonald islands', 'kiribati', 'marshall islands', 'micronesia', 'nauru', 'new caledonia', 'new zealand', 'niue', 'norfolk island', 'northern mariana islands', 'palau', 'papua new guinea', 'pitcairn', 'samoa', 'solomon islands', 'tokelau', 'tonga', 'tuvalu', 'united states minor outlying islands', 'vanuatu', 'wallis and futuna islands'],\n",
    "                        'south america': ['argentina', 'bolivia', 'bouvet island', 'brazil', 'chile', 'colombia', 'ecuador', 'falkland islands', 'french guiana', 'guyana', 'paraguay', 'peru', 'south georgia and the south sandwich islands', 'suriname', 'uruguay', 'venezuela']}\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Elapsed time: {elapsed_time:.5f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7819159-3f3c-41b7-97b2-ae34e2e5e751",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hs_uuid_state_country.csv')\n",
    "origianl_data = pd.read_csv('hs_uuid_state_country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bed706e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time lowercase: 0.12636 seconds\n",
      "Elapsed time remove_diacritics: 2.69945 seconds\n",
      "Elapsed time fix_abv: 9.62404 seconds\n",
      "Elapsed time total: 17.56184 seconds\n",
      "Number of unique values in uuid: 99307\n",
      "Number of unique values in State/Region: 345\n",
      "Number of unique values in Country/Region: 129\n",
      "Number of unique values in Continent: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "cols_to_copy = ['uuid', 'State/Region','Country/Region']\n",
    "\n",
    "# create a new DataFrame with the selected columns\n",
    "hs_contacts_state_country = df.loc[:, cols_to_copy].copy()\n",
    "\n",
    "\n",
    "# make lower and clean from punctuations\n",
    "start_time_lowercase = time.time()\n",
    "hs_contacts_state_country[\"State/Region\"] = hs_contacts_state_country[\"State/Region\"].astype(str)\n",
    "hs_contacts_state_country[\"Country/Region\"]= hs_contacts_state_country[\"Country/Region\"].astype(str)\n",
    "\n",
    "\n",
    "hs_contacts_state_country[\"State/Region\"] = hs_contacts_state_country[\"State/Region\"].str.lower().str.strip()\n",
    "hs_contacts_state_country[\"Country/Region\"] = hs_contacts_state_country[\"Country/Region\"].str.lower().str.strip()\n",
    "\n",
    "\n",
    "end_time_lowercase = time.time()\n",
    "elapsed_time_lowercase = end_time_lowercase - start_time_lowercase\n",
    "print(f\"Elapsed time lowercase: {elapsed_time_lowercase:.5f} seconds\")\n",
    "\n",
    "#letters not in english\n",
    "\n",
    "start_time_remove_diacritics = time.time()\n",
    "\n",
    "hs_contacts_state_country[\"State/Region\"] = hs_contacts_state_country[\"State/Region\"].apply(remove_diacritics)\n",
    "hs_contacts_state_country[\"Country/Region\"] = hs_contacts_state_country[\"Country/Region\"].apply(remove_diacritics)\n",
    "\n",
    "end_time_remove_diacritics = time.time()\n",
    "elapsed_time_remove_diacritics = end_time_remove_diacritics - start_time_remove_diacritics\n",
    "print(f\"Elapsed time remove_diacritics: {elapsed_time_remove_diacritics:.5f} seconds\")\n",
    "\n",
    "\n",
    "#change long state name to abv for us and canada\n",
    "start_time_fix_abv = time.time()\n",
    "\n",
    "hs_contacts_state_country['State/Region'] = hs_contacts_state_country['State/Region'].replace(us_state_to_abbrev)\n",
    "\n",
    "\n",
    "hs_contacts_state_country = hs_contacts_state_country.apply(replace_canada_state_name, axis=1)\n",
    "\n",
    "#clean country - change united states to US, UK/united kingdom to england\n",
    "\n",
    "hs_contacts_state_country['Country/Region'] = hs_contacts_state_country['Country/Region'].replace(us_uk_fix)\n",
    "\n",
    "#change all countries to US and Canada if they have a state\n",
    "\n",
    "hs_contacts_state_country.loc[hs_contacts_state_country['State/Region'].isin(list(us_state_to_abbrev.values())), 'Country/Region'] = 'us'\n",
    "hs_contacts_state_country.loc[hs_contacts_state_country['State/Region'].isin(list(canada_states.values())), 'Country/Region'] = 'canada'\n",
    "\n",
    "#if there is a us state in the country change it to us and put the state in the state column\n",
    "\n",
    "hs_contacts_state_country.loc[hs_contacts_state_country['Country/Region'].isin(list(us_state_to_abbrev.values())), 'Country/Region'] = 'us'\n",
    "\n",
    "\n",
    "end_time_fix_abv = time.time()\n",
    "elapsed_time_fix_abv = end_time_fix_abv - start_time_fix_abv\n",
    "print(f\"Elapsed time fix_abv: {elapsed_time_fix_abv:.5f} seconds\")\n",
    "\n",
    "#check if there is a name of a country in the state column\n",
    "hs_contacts_state_country = hs_contacts_state_country.apply(move_state_name, axis=1)\n",
    "\n",
    "### create a dict to use for mapping the region - new project\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "#fix nan string in country or state\n",
    "hs_contacts_state_country['State/Region'] = hs_contacts_state_country['State/Region'].replace('nan', '')\n",
    "hs_contacts_state_country['Country/Region'] = hs_contacts_state_country['Country/Region'].replace('nan', '')\n",
    "\n",
    "#Add the continent of each country\n",
    "hs_contacts_state_country['Continent'] = hs_contacts_state_country['Country/Region'].apply(get_continent)\n",
    "\n",
    "elapsed_time_total = end_time - start_time\n",
    "print(f\"Elapsed time total: {elapsed_time_total:.5f} seconds\")\n",
    "\n",
    "for column in hs_contacts_state_country.columns:\n",
    "    num_unique = hs_contacts_state_country[column].nunique()\n",
    "    print(f\"Number of unique values in {column}: {num_unique}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f85fa862-7298-42ad-a28a-7a2448a84bce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in uuid: 99307\n",
      "Number of unique values in State/Region: 478\n",
      "Number of unique values in Country/Region: 158\n"
     ]
    }
   ],
   "source": [
    "for column in df.columns:\n",
    "    num_unique = df[column].nunique()\n",
    "    print(f\"Number of unique values in {column}: {num_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46d58b94-f87e-419e-bb34-f00d1c8f3f53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When ignoring lowercase, calculating letter changes\n",
      "Column uuid has 0 cells with changes.\n",
      "Column State/Region has 28310 cells with changes.\n",
      "Column Country/Region has 70127 cells with changes.\n"
     ]
    }
   ],
   "source": [
    "#CHECK THE AFFECTED COLUMNS\n",
    "df1 = df.copy()\n",
    "\n",
    "df1[\"State/Region\"] = df1[\"State/Region\"].astype(str)\n",
    "df1[\"Country/Region\"]= df1[\"Country/Region\"].astype(str)\n",
    "\n",
    "df1[\"State/Region\"] = df1[\"State/Region\"].str.lower().str.strip()\n",
    "df1[\"Country/Region\"] = df1[\"Country/Region\"].str.lower().str.strip()\n",
    "\n",
    "print('When ignoring lowercase, calculating letter changes')\n",
    "for col in hs_contacts_state_country.columns:\n",
    "    if col not in df1.columns:\n",
    "        continue  # skip columns that are not in the old dataframe\n",
    "    num_changes = (df1[col] != hs_contacts_state_country[col]).sum()\n",
    "    print(f'Column {col} has {num_changes} cells with changes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f976270",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'My-Projects/state_country_output'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m timestamp \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mhs_contacts_state_country\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMy-Projects/state_country_output/update_state_country_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtimestamp\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:3720\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3709\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3711\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3712\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3713\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3717\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3718\u001b[0m )\n\u001b[0;32m-> 3720\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3723\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3724\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3725\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3734\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3735\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3737\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/formats/format.py:1189\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1168\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1171\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1172\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1187\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1188\u001b[0m )\n\u001b[0;32m-> 1189\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1192\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:734\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 734\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    738\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py:597\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    595\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 597\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'My-Projects/state_country_output'"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "hs_contacts_state_country.to_csv(f'My-Projects/state_country_output/update_state_country_{timestamp}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e829f4-5856-4565-995f-fbf508d69909",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_unique_cells = origianl_data[\"State/Region\"].nunique() +  origianl_data[\"Country/Region\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "074c0ffa-d10e-4ce1-b2ea-8e858ab0268c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Record ID has 0 cells with changes.\n",
      "Column State/Region has 98482 cells with changes.\n",
      "Column Country/Region has 99161 cells with changes.\n"
     ]
    }
   ],
   "source": [
    "for col in hs_contacts_state_country.columns:\n",
    "    if col not in origianl_data.columns:\n",
    "        continue  # skip columns that are not in the old dataframe\n",
    "    num_changes = (origianl_data[col] != hs_contacts_state_country[col]).sum()\n",
    "    print(f'Column {col} has {num_changes} cells with changes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "879eb0a3-2f6b-4722-bbe3-5c6441cb7ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comparason_df = {\n",
    "    'dataset': ['original data on hs', 'new output'],\n",
    "    'unique_record_id': [origianl_data['Record ID'].nunique(), hs_contacts_state_country['Record ID'].nunique()],\n",
    "    'unique_record_state': [origianl_data[\"State/Region\"].nunique(), hs_contacts_state_country[\"State/Region\"].nunique()],\n",
    "    'unique_record_country': [origianl_data[\"Country/Region\"].nunique(), hs_contacts_state_country[\"Country/Region\"].nunique()]\n",
    "}\n",
    "\n",
    "comparason_df = pd.DataFrame(comparason_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "28a2467c-4364-47a8-86a5-0e3a57acb039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>unique_record_id</th>\n",
       "      <th>unique_record_state</th>\n",
       "      <th>unique_record_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>original data on hs</td>\n",
       "      <td>99307</td>\n",
       "      <td>478</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new output</td>\n",
       "      <td>99307</td>\n",
       "      <td>345</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               dataset  unique_record_id  unique_record_state  \\\n",
       "0  original data on hs             99307                  478   \n",
       "1           new output             99307                  345   \n",
       "\n",
       "   unique_record_country  \n",
       "0                    158  \n",
       "1                    129  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparason_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a758402d-a292-42a8-a493-8b88decbb198",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "comparason_df.to_csv(f'comparason_df{timestamp}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b089f1a2-833b-4195-afc3-36ad693f3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9b212d89-55c3-4c0b-911b-07e3123a21c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in Record ID: 99307\n",
      "Number of unique values in First Name: 14702\n",
      "Number of unique values in Last Name: 45618\n",
      "Number of unique values in Email: 95784\n",
      "Number of unique values in State/Region: 422\n",
      "Number of unique values in Country/Region: 139\n"
     ]
    }
   ],
   "source": [
    "for column in dftest.columns:\n",
    "    num_unique = dftest[column].nunique()\n",
    "    print(f\"Number of unique values in {column}: {num_unique}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "95bfd60e-ad64-4cd7-b122-1242365dd30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#percent that changed\n",
    "num_changes_state = (df1[\"State/Region\"] != hs_contacts_state_country[\"State/Region\"]).sum()\n",
    "num_changes_country = (df1[\"Country/Region\"] != hs_contacts_state_country[\"Country/Region\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "02f1c263-eebf-4556-988e-72afbb9b7319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28310"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_changes_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "15ff97a4-fd81-456f-8e91-28eb1c5e59a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70127"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_changes_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "29117df1-5ae9-45a3-a623-00525c664fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "percente_of_cell_affected_state = (num_changes_state / origianl_data[\"State/Region\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "18666c27-110b-4f66-95d1-e5400de024b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "percente_of_cell_affected_country = (num_changes_country / origianl_data[\"Country/Region\"].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "fd59d0d9-4aaf-4625-9d0e-a0d20f5ad3a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>original_data_row_count</th>\n",
       "      <th>new_data_affected_rows</th>\n",
       "      <th>percent_of_affected_rows</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>state</td>\n",
       "      <td>74242</td>\n",
       "      <td>28310</td>\n",
       "      <td>0.381321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>84483</td>\n",
       "      <td>70127</td>\n",
       "      <td>0.830072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type  original_data_row_count  new_data_affected_rows  \\\n",
       "0    state                    74242                   28310   \n",
       "1  country                    84483                   70127   \n",
       "\n",
       "   percent_of_affected_rows  \n",
       "0                  0.381321  \n",
       "1                  0.830072  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affected_cells_df = {\n",
    "    'type': ['state', 'country'],\n",
    "    'original_data_row_count': [origianl_data[\"State/Region\"].count(), origianl_data[\"Country/Region\"].count()],\n",
    "    'new_data_affected_rows': [num_changes_state, num_changes_country],\n",
    "    'percent_of_affected_rows': [percente_of_cell_affected_state, percente_of_cell_affected_country]\n",
    "}\n",
    "\n",
    "affected_cells_df = pd.DataFrame(affected_cells_df)\n",
    "affected_cells_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "32a2c806-c29f-4c4f-89c8-25c26ea64304",
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_cells_df = {\n",
    "    'type': ['state', 'country'],\n",
    "    'original_data_row_count': [origianl_data[\"State/Region\"].count(), origianl_data[\"Country/Region\"].count()],\n",
    "    'new_data_affected_rows': [num_changes_state, num_changes_country],\n",
    "    'percent_of_affected_rows': [percente_of_cell_affected_state, percente_of_cell_affected_country]\n",
    "}\n",
    "\n",
    "affected_cells_df = pd.DataFrame(affected_cells_df)\n",
    "affected_cells_df\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "affected_cells_df.to_csv(f'affected_cells_{timestamp}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1680b-774e-4fdd-8287-846548b28fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
